---
title: AI
type: note
tags:
	- AI
---

!!! note "🚧  Under renovation"

- [[computational-techniques-to-reduce-lab-time]]

## Some early thoughts on LLMs

[[early-llm-value-thoughts]]

My current take/suspicion on LLMs is that they are over-blown, useful but over-blown. Likely to be widely used badly and generate negative consequences due to broken societal/commercial systems and bad actors. Actors that leverage the inherent limitations of LLMs for immediate gain. 

There is a small chance that LLMs may have some surprising emergent capabilities, especially if they are able to be used creatively and contextually by networks, communities, and individuals.

Sources that have influenced my thinking, include:

- [AI and Software Quality](https://softwarecrisis.dev/letters/ai-and-software-quality/)
- [Ayyyyy Eyeeeee](https://doctorow.medium.com/ayyyyyy-eyeeeee-4ac92fa2eed) - from Cory Doctorow that uses prior tech experience ([criti-hype](https://sts-news.medium.com/youre-doing-it-wrong-notes-on-criticism-and-technology-hype-18b08b4307e5)) and current LLM happenings to explore how they'll be used for [enshittification](https://pluralistic.net/2023/01/21/potemkin-ai/#hey-guys) to argue the idea that rather than posing an existential risk, LLMs "a product of limited utility that has been shoehorned into high-stakes applicaions that it is unsuited to perform"

## About LLMs

- [[llm-types]] - over of different LLM types
- [Weird world of LLMS](https://simonwillison.net/2023/Aug/3/weird-world-of-llms/) - interesting presentation giving different perspectives.

## Presentations 

- [[building-ai-applications-based-on-learning-research]] - Q&A with Khan Academy on their use of LLMs

## Prompt engineering

- [[prompt-engineering]]
- [[prompt-engineering-for-educators]]
- [[problem-prompts]]

## Explorations

- [[first-llm-api-experiments]] - Figure out how and if basic APIs for LLMs can be used to "template" prompt engineering
- [[customising-llms]] - if and how do you customise a LLM using your own documents.
	- [[privateGPT]] - experiment running local LLM with document embeddings
- [[compare-chatgpt-qlora]]
- [[LangChain]]

## Questions and resources for further exploration

- If, why and how to run a LLM locally - would generally require a good set of content to train it with???
- 

[//begin]: # "Autogenerated link references for markdown compatibility"
[computational-techniques-to-reduce-lab-time]: research/computational-techniques-to-reduce-lab-time "Computational techniques to reduce lab time"
[early-llm-value-thoughts]: early-llm-value-thoughts "Early LLMm value thoughts"
[llm-types]: llm-types "LLM Types"
[building-ai-applications-based-on-learning-research]: building-ai-applications-based-on-learning-research "Building AI applications based on learning research"
[prompt-engineering]: prompt-engineering "Prompt engineering"
[prompt-engineering-for-educators]: prompt-engineering-for-educators "prompt-engineering-for-educators"
[problem-prompts]: problem-prompts "Problem prompts"
[first-llm-api-experiments]: explorations/first-llm-api-experiments "First experiments with LLM APIs"
[customising-llms]: explorations/customising-llms "Customising LLMs"
[privateGPT]: explorations/privateGPT "PrivateGPT"
[compare-chatgpt-qlora]: explorations/compare-chatgpt-qlora "Explorations in comparing ChatGPT & QLoRA"
[LangChain]: explorations/LangChain "LangChain"
[//end]: # "Autogenerated link references"